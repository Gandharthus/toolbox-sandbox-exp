from __future__ import annotations

from datetime import date, datetime
from typing import Any, Literal

from pydantic import BaseModel, Field, ConfigDict


JsonScalar = str | int | float | bool | date | datetime


# -----------------------------------------------------------------------------
# Leaf bodies (used inside query containers)
# -----------------------------------------------------------------------------

class MatchFieldOptions(BaseModel):
    """
    Options for a single field in a `match` query.

    LLM guidance:
      - Use this when you need per-field controls like operator or fuzziness.
      - Equivalent JSON shape inside container:
        {"match": {"<field>": {"query": "...", "operator": "and"}}}

    Important params:
      query: The search text/value for the field (analyzed for full-text). 
      operator: Logical operator between analyzed terms ("and" | "or"). Defaults to "or".
      minimum_should_match: Require at least this many terms to match. May be "2" or "75%".
      fuzziness: Allow edit distance (e.g., "AUTO", 1, 2) for typo tolerance.
      prefix_length: Leading chars not considered for fuzziness.
      max_expansions: Max variations generated by fuzziness.
      analyzer: Override analyzer for this query.
      boost: Score multiplier for this clause.
    """
    query: JsonScalar = Field(..., description="Analyzed input to match against this field.")
    operator: Literal["and", "or"] | None = Field(
        None, description="Logical operator between analyzed terms."
    )
    minimum_should_match: int | str | None = Field(
        None, description='Minimum number/percent of terms that must match, e.g. 2 or "75%".'
    )
    fuzziness: int | Literal["AUTO"] | None = Field(
        None, description='Edit distance allowed; e.g. "AUTO", 1, 2.'
    )
    prefix_length: int | None = Field(
        None, description="Number of initial characters exempt from fuzziness."
    )
    max_expansions: int | None = Field(
        None, description="Upper bound on term variations generated by fuzziness."
    )
    analyzer: str | None = Field(None, description="Analyzer to use instead of the field’s analyzer.")
    boost: float | None = Field(None, description="Score multiplier for this field query.")

    model_config = ConfigDict(extra="forbid")


class TermValue(BaseModel):
    """
    Verbose object form used in `term` queries for per-field control.

    LLM guidance:
      - Prefer the compact form when no boost is needed:
        {"term": {"status": "active"}}
      - Use this object form for boosts:
        {"term": {"status": {"value": "active", "boost": 2.0}}}
    """
    value: JsonScalar = Field(..., description="Exact value to match (non-analyzed).")
    boost: float | None = Field(None, description="Score multiplier for this term.")

    model_config = ConfigDict(extra="forbid")


class RangeOps(BaseModel):
    """
    Range operators for a single field in a `range` query.

    LLM guidance:
      - Use ISO datetimes or date math (e.g., 'now-7d/d') for time fields.
      - Example:
        {"range": {"timestamp": {"gte": "now-7d/d", "lt": "now/d"}}}
    """
    gte: JsonScalar | None = Field(None, description="Greater than or equal.")
    gt: JsonScalar | None = Field(None, description="Greater than (strict).")
    lte: JsonScalar | None = Field(None, description="Less than or equal.")
    lt: JsonScalar | None = Field(None, description="Less than (strict).")
    format: str | None = Field(None, description="Date format string for parsing inputs.")
    time_zone: str | None = Field(None, description="Time zone to use when parsing dates.")
    boost: float | None = Field(None, description="Score multiplier for this range.")

    model_config = ConfigDict(extra="forbid")


# -----------------------------------------------------------------------------
# Query containers (each is a single-key object, matching Elasticsearch DSL)
# -----------------------------------------------------------------------------

class MatchQuery(BaseModel):
    """
    Container for a `match` query (full-text on a single field).

    JSON shape:
      {"match": {"<field>": <text or MatchFieldOptions>}}

    LLM usage:
      - Good default for full-text search on one field.
      - For multi-field text search, prefer `MultiMatchQuery`.
    """
    match: dict[str, JsonScalar | MatchFieldOptions] = Field(
        ..., description="Map of one field name to its match value/options."
    )
    model_config = ConfigDict(extra="forbid")


class MultiMatchQuery(BaseModel):
    """
    Container for a `multi_match` query (full-text across multiple fields).

    JSON shape:
      {"multi_match": {"query": "...", "fields": ["title^2","body"], "type": "best_fields"}}

    LLM usage:
      - Use for multi-field text search.
      - You can boost fields via '^' (e.g., 'title^2').
      - `type` can be 'best_fields' (default), 'most_fields', 'cross_fields', 'phrase', 'phrase_prefix'.
    """
    multi_match: dict[str, Any] = Field(
        ..., description="Options for the multi_match query (query, fields, type, etc.)."
    )
    model_config = ConfigDict(extra="forbid")

    @classmethod
    def build(
        cls,
        query: str,
        fields: list[str],
        type: Literal["best_fields", "most_fields", "cross_fields", "phrase", "phrase_prefix"] | None = None,
        tie_breaker: float | None = None,
        operator: Literal["and", "or"] | None = None,
        minimum_should_match: int | str | None = None,
        boost: float | None = None,
        **kwargs: Any,
    ) -> "MultiMatchQuery":
        """
        Convenience builder that only sets provided options (keeps emitted JSON clean).
        """
        payload: dict[str, Any] = {"query": query, "fields": fields}
        if type is not None:
            payload["type"] = type
        if tie_breaker is not None:
            payload["tie_breaker"] = tie_breaker
        if operator is not None:
            payload["operator"] = operator
        if minimum_should_match is not None:
            payload["minimum_should_match"] = minimum_should_match
        if boost is not None:
            payload["boost"] = boost
        payload.update(kwargs)
        return cls(multi_match=payload)


class TermQuery(BaseModel):
    """
    Container for a `term` query (exact match on a single field).

    JSON shapes:
      Compact: {"term": {"status": "active"}}
      Verbose: {"term": {"status": {"value": "active", "boost": 2.0}}}

    LLM usage:
      - Use for keyword, numeric, boolean, or date fields (non-analyzed exact value).
      - For full-text, prefer `match` or `multi_match`.
    """
    term: dict[str, JsonScalar | TermValue] = Field(
        ..., description="Map of one field name to an exact value or TermValue object."
    )
    model_config = ConfigDict(extra="forbid")


class TermsQuery(BaseModel):
    """
    Container for a `terms` query (exact match against any of several values).

    JSON shape:
      {"terms": {"status": ["draft", "published"]}}

    LLM usage:
      - Use when matching a field against a list of exact values (IN query).
    """
    terms: dict[str, list[JsonScalar]] = Field(
        ..., description="Map of one field name to a list of allowed values."
    )
    model_config = ConfigDict(extra="forbid")


class RangeQuery(BaseModel):
    """
    Container for a `range` query.

    JSON shape:
      {"range": {"timestamp": {"gte": "2025-01-01", "lt": "2026-01-01"}}}

    LLM usage:
      - Use for numeric or date windows (supports date math like 'now-7d/d').
    """
    range: dict[str, RangeOps] = Field(
        ..., description="Map of one field name to RangeOps operators."
    )
    model_config = ConfigDict(extra="forbid")


class ExistsQuery(BaseModel):
    """
    Container for an `exists` query (documents where a field is present).

    JSON shape:
      {"exists": {"field": "author"}}

    LLM usage:
      - Great in filter contexts to ensure a field is populated.
    """
    exists: dict[Literal["field"], str] = Field(
        ..., description='Object with key "field" naming the field that must exist.'
    )
    model_config = ConfigDict(extra="forbid")


class MatchAllQuery(BaseModel):
    """
    Container for a `match_all` query (matches every document).

    JSON shapes:
      {"match_all": {}}
      {"match_all": {"boost": 1.2}}

    LLM usage:
      - Use as a base with filters, or for “return everything” requests.
    """
    match_all: dict[str, Any] = Field(
        default_factory=dict, description="Optional object; may contain 'boost'."
    )
    model_config = ConfigDict(extra="forbid")


class IdsQuery(BaseModel):
    """
    Container for an `ids` query (match by document IDs).

    JSON shape:
      {"ids": {"values": ["1","2","3"]}}

    LLM usage:
      - Use for direct ID lookups or to constrain results to a known set.
    """
    ids: dict[Literal["values"], list[str]] = Field(
        ..., description='Object with key "values" listing document IDs.'
    )
    model_config = ConfigDict(extra="forbid")


# -----------------------------------------------------------------------------
# Recursive bool query + union of all query types
# -----------------------------------------------------------------------------

# Forward-declare union for recursion
Query = (
    MatchQuery
    | MultiMatchQuery
    | TermQuery
    | TermsQuery
    | RangeQuery
    | ExistsQuery
    | MatchAllQuery
    | IdsQuery
    | "BoolQuery"
)

class BoolBody(BaseModel):
    """
    Inner body for a `bool` query. Combines other queries using boolean logic.

    LLM guidance:
      - `must`: scoring, documents MUST match all queries here.
      - `filter`: non-scoring (cached) filters; use for constraints (faster).
      - `should`: optional scoring clauses; set `minimum_should_match` if you
                  need at least N/percent of these to match.
      - `must_not`: negate (documents MUST NOT match).
      - You can nest `BoolQuery` inside any of these lists.

    Example:
      {
        "bool": {
          "must":   [{"match": {"title": "solar"}}],
          "filter": [{"range": {"date": {"gte": "now-30d/d"}}}],
          "should": [{"term": {"lang": "en"}}],
          "minimum_should_match": 1
        }
      }
    """
    must: list[Query] | None = Field(None, description="All must match; contributes to score.")
    filter: list[Query] | None = Field(None, description="All must match; does NOT affect score.")
    should: list[Query] | None = Field(None, description="Optional; affects score unless minimum_should_match is set.")
    must_not: list[Query] | None = Field(None, description="Documents must NOT match these.")
    minimum_should_match: int | str | None = Field(
        None, description='Minimum number/percent of `should` clauses that must match, e.g. 1 or "75%".'
    )
    boost: float | None = Field(None, description="Score multiplier for the bool query as a whole.")

    model_config = ConfigDict(extra="forbid")


class BoolQuery(BaseModel):
    """
    Container for a `bool` query.

    JSON shape:
      {"bool": {"must": [...], "filter": [...], "should": [...], "must_not": [...], "minimum_should_match": 1}}

    LLM usage:
      - Primary composition tool for complex queries; supports nesting.
      - Prefer `filter` for hard constraints (date ranges, terms) to avoid score noise.
    """
    bool: BoolBody = Field(..., description="Boolean composition of other queries.")
    model_config = ConfigDict(extra="forbid")


# finalize recursive references for pydantic v2
BoolBody.model_rebuild()
BoolQuery.model_rebuild()
Query = (
    MatchQuery
    | MultiMatchQuery
    | TermQuery
    | TermsQuery
    | RangeQuery
    | ExistsQuery
    | MatchAllQuery
    | IdsQuery
    | BoolQuery
)


# -----------------------------------------------------------------------------
# Minimal _search request wrapper
# -----------------------------------------------------------------------------

class SearchRequest(BaseModel):
    """
    Minimal wrapper for the Elasticsearch `_search` request body.

    LLM guidance:
      - Always set `query` to one of the query containers above.
      - Use `size` to limit hits. Use `from` (as `from_` here) for pagination.
      - Keep output compact: `model_dump(by_alias=True, exclude_none=True)`.

    Example:
      q = BoolQuery(
        bool=BoolBody(
          must=[MatchQuery(match={"title": MatchFieldOptions(query="wind power", operator="and")})],
          filter=[RangeQuery(range={"published_at": RangeOps(gte="now-30d/d")})],
          should=[TermQuery(term={"lang": "en"})],
          minimum_should_match=1
        )
      )
      req = SearchRequest(query=q, size=25, **{"from": 0})
      body = req.model_dump(by_alias=True, exclude_none=True)
    """
    query: Query = Field(..., description="A single Query DSL container (match, bool, range, etc.).")
    size: int | None = Field(None, description="Maximum number of hits to return.")
    from_: int | None = Field(default=None, alias="from", description="Offset for pagination (use with `size`).")

    model_config = ConfigDict(populate_by_name=True, extra="forbid")
